{"params": {"action": "query", "titles": "UALink", "prop": "extracts", "exintro": "0", "explaintext": "1", "exsectionformat": "plain", "format": "json", "utf8": "1"}, "data": {"batchcomplete": "", "query": {"pages": {"78261088": {"pageid": 78261088, "ns": 0, "title": "UALink", "extract": "Ultra Accelerator Link (UALink) is an open specification for a die-to-die interconnect and serial bus between AI accelerators. It is co-developed by Alibaba, AMD, Apple, Astera Labs, AWS, Cisco, Google, Hewlett Packard Enterprise, Intel, Meta, Microsoft and Synopsys. The UALink Consortium officially incorporated as an organization and electronics industry consortium in 2024, for promoting and advancing UALink.\nIts first specification will provide interconnectivity specifically for a scalable network. The initial 1.0 version 200Gbps UALink specification, is based on the IEEE P802.3dj 200 Gb/s (Ultra Ethernet) PHY Layer. Each system node is made up of a host and as many accelerators as needed, and is managed by one OS image. The accelerators can be connected to the host using a variety of interconnect protocols (CXL, PCIe, XGMI, CHI c2c, Infinity Fabric). UALink Switches (ULS) connect up to 1024 accelerators within an AI 'pod', where each Accelerator is assigned a unique 10-bit routing identifier. Each UALink Switch port connects to a distinct Accelerator. AMD Infinity Fabric is expected to be the main shared-memory protocol.\nThe specification was due to be available to Contributor Members in 2024. The 1.0 version (UALink_200) was released to the public in 2025. Members of the public can download an \"evaluation copy\" after providing contact information."}}}}, "fetched_at": "2026-01-31T14:57:30.765427"}