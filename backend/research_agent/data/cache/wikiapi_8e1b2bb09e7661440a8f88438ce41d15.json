{"params": {"action": "query", "titles": "CUDA", "prop": "extracts", "exintro": "0", "explaintext": "1", "exsectionformat": "plain", "format": "json", "utf8": "1"}, "data": {"batchcomplete": "", "query": {"pages": {"7933386": {"pageid": 7933386, "ns": 0, "title": "CUDA", "extract": "CUDA (Compute Unified Device Architecture) is a proprietary parallel computing platform and application programming interface (API) that allows software to use certain types of graphics processing units (GPUs) for accelerated general-purpose processing, significantly broadening their utility in scientific and high-performance computing. CUDA was created by Nvidia starting in 2004 and was officially released in 2007. When it was first introduced, the name was an acronym for Compute Unified Device Architecture, but Nvidia later dropped the common use of the acronym and now rarely expands it.\nCUDA is both a software layer that manages data, giving direct access to the GPU and CPU as necessary, and a library of APIs that enable parallel computation for various needs. In addition to drivers and runtime kernels, the CUDA platform includes compilers, libraries and developer tools to help programmers accelerate their applications.\nCUDA is written in the C programming language but is designed to work with a wide array of other programming languages including C++, Fortran, Python and Julia. This accessibility makes it easier for specialists in parallel programming to use GPU resources, in contrast to prior APIs like Direct3D and OpenGL, which require advanced skills in graphics programming. CUDA-powered GPUs also support programming frameworks such as OpenMP, OpenACC and OpenCL."}}}}, "fetched_at": "2026-01-31T15:19:44.549373"}